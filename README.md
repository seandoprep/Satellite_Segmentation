> Code is still on working. Please wait for final version.

# ğŸ›°ï¸Satellite_SegmentationğŸ›°ï¸ : Segmentation Framework Using PyTorch for Satellite Imagery.

## About the Project
- This code is originally built for segmenting offshore aquaculture facilities in the Southern Sea of South Korea, but you can just apply this pipeline into any kind of satellite segmentation tasks. 
- You can get your target segmentation result with non-processed Satellite Imagery and target mask.
- Code will be updated constantly. If you have any advice or questions, please feel free to contact me via email(sean3819@yonsei.ac.kr).

## Requirements
</br>

### Conda virtual environment setup (recommend python 3.9.18.ver )

```
conda create -n [environment name] --file [this file]
conda activate [environment name]
```
</br>

### Git clone repo

```
git clone https://github.com/seandoprep/Satellite_Segmentation.git
```

Clone this repo into your own computer. You can just create data directory by yourself. 

</br>

And finally the directory hierarchy is configured as,

```
Satellite_Segmentation
â”œâ”€data
â”‚  â””â”€Train
â”‚      â””â”€ENVI
â”‚          â”œâ”€Image
â”‚          â”œâ”€Mask
â”‚          â””â”€original_nc
â”œâ”€models
â”‚  â”œâ”€modules
â”‚  â””â”€models
â”œâ”€outputs
â”‚  â”œâ”€inference_output
â”‚  â”œâ”€test_output
â”‚  â””â”€train_output
â”œâ”€utils
â”‚  â”œâ”€metrics.py
â”‚  â”œâ”€save_data.py
â”‚  â”œâ”€util.py
â”‚  â””â”€visualize.py
â”œâ”€weights
â”‚  â””â”€train_result
â”œâ”€band_analysis.py
â”œâ”€dataset.py
â”œâ”€loss.py
â”œâ”€scheduler.py
â”œâ”€train.py
â”œâ”€test.py
â”œâ”€inference.py
â””â”€requirements.txt

```

---

## Dataset
</br>

### Data Format
- Currently, this code can only handle ENVI type Satellite images. 
- Code for handling other types of data(netcdf, tiff, etc..) will also be added
- Data should be large original satellite image without cutting. Built-in algorithm will divide Large original images into 256 width, height images.
- original nc data needs for extracting lat/lon information.
- Using all of the huge satellite data can lead to a data distribution imbalance problem. 
- Therefore, after sampling the deep learning data based on the target mask, the data of the non-target area may be randomly added.

```
data
â”œâ”€â”€ Train
â”‚      â”œâ”€â”€ ENVI
â”‚      â”‚      â”œâ”€â”€ Image
â”‚      â”‚      â”‚      â”œâ”€â”€ NDWI.hdr
â”‚      â”‚      â”‚      â”œâ”€â”€ NDWI.img
â”‚      â”‚      â”‚      â”œâ”€â”€ NIR.hdr
â”‚      â”‚      â”‚      â”œâ”€â”€ NIR.img
â”‚      â”‚      â”‚      â””â”€â”€ .....
â”‚      â”‚      â”œâ”€â”€ Mask
â”‚      â”‚      â”‚      â”œâ”€â”€ Mask.hdr
â”‚      â”‚      â”‚      â””â”€â”€ Mask.img
â”‚      â”‚      â”œâ”€â”€ original_nc
â””â”€â”€    â””â”€â”€    â””â”€â”€    â””â”€â”€ original.nc

```
</br>

### Sample data(will be added)



## Train/Test/Inference

### Supported model

- In order to handle multi-channel data, I add some feature extractor block in front of some models. 
- U-Net, U2-Net, DeepLabv3+, ResUNet++, Attention U-Net, Mdoaunet, RaftNet are now available

### Train
</br>
python train.py -D [data directory] -M [model name] -E [num epochs] -L [learning rate] -B [batch size] -S [early stop]
</br>

### Test
</br>
python test.py -D [data directory] -M [model name] -P [model path]
</br>

### Inference
</br>
python train.py -D [data directory] -M [model name] -P [model path] -B [batch size]
</br>

### Performance(will be added) : 
</br>


## Qualitative results(will be added)

</br>


## Reference(will be added)
Thanks to,
https://github.com/usuyama/pytorch-unet
https://github.com/xuebinqin/U-2-Net
https://github.com/rishikksh20/ResUnet
https://github.com/LeeJunHyun/Image_Segmentation
https://github.com/mukund-ks/DeepLabV3Plus-PyTorch
https://github.com/Jichao-Wang/MDOAU-net/blob/main/MDOAU_net.py
https://www.mdpi.com/2072-4292/14/18/4587